{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfkECqUQ3NFUvmk3LICFua",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvinogradskaya/DL_HW4_RNN/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VihIkkatOaVV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from datetime import datetime\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# ========================\n",
        "# 2. Параметры\n",
        "# ========================\n",
        "MAX_USERS = 3\n",
        "SEQ_LENGTH = 10\n",
        "EMBEDDING_DIM = 16\n",
        "LSTM_UNITS = 64\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 3\n",
        "TEST_SIZE = 0.3\n",
        "DATA_PATH = \"/content/drive/My Drive/Colab Notebooks/Data/\"\n",
        "GRID_SIZE_LARGE = 0.0045\n",
        "GRID_SIZE_SMALL = 0.000045"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK7PTC9DOgPz",
        "outputId": "e2e830fe-f6fd-4bfc-d332-47e04fb9a898"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 3. Утилиты\n",
        "# ========================\n",
        "def haversine(coord1, coord2):\n",
        "    R = 6371000  # Earth radius in meters\n",
        "    lat1, lon1 = coord1\n",
        "    lat2, lon2 = coord2\n",
        "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
        "    d_phi = phi2 - phi1\n",
        "    d_lambda = math.radians(lon2 - lon1)\n",
        "    a = math.sin(d_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(d_lambda / 2)**2\n",
        "    return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "\n",
        "def sinusoidal_time_embedding(timestamps, dim=16):\n",
        "    emb = []\n",
        "    for ts in timestamps:\n",
        "        emb_i = []\n",
        "        for i in range(dim // 2):\n",
        "            angle = ts.timestamp() / (10000 ** (2 * i / dim))\n",
        "            emb_i.append(math.sin(angle))\n",
        "            emb_i.append(math.cos(angle))\n",
        "        emb.append(emb_i)\n",
        "    return torch.tensor(emb, dtype=torch.float)\n",
        "\n",
        "def create_grid(lat, lon, grid_size):\n",
        "    return int(lat / grid_size), int(lon / grid_size)"
      ],
      "metadata": {
        "id": "GdgXErDgOjQh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 4. Загрузка и обработка данных Geolife\n",
        "# ========================\n",
        "def load_and_preprocess_data(data_path, max_users=MAX_USERS):\n",
        "    data = []\n",
        "    user_dirs = sorted(os.listdir(data_path))[:max_users]\n",
        "    for user in tqdm(user_dirs, desc=\"Loading users\"):\n",
        "        traj_dir = os.path.join(data_path, user, 'Trajectory')\n",
        "        traj_files = sorted([f for f in os.listdir(traj_dir) if f.endswith('.plt')])\n",
        "        for traj_file in traj_files:\n",
        "            df = pd.read_csv(\n",
        "                os.path.join(traj_dir, traj_file),\n",
        "                skiprows=6,\n",
        "                header=None,\n",
        "                usecols=[0, 1, 3, 5, 6],\n",
        "                names=['lat', 'lon', 'alt', 'date', 'time']\n",
        "            )\n",
        "            df['user'] = user\n",
        "            data.append(df)\n",
        "\n",
        "    df = pd.concat(data, ignore_index=True)\n",
        "    df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
        "    df.sort_values(by=['user', 'datetime'], inplace=True)\n",
        "    df = df[(df['lat'] != 0) & (df['lon'] != 0)].ffill()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    df[['lat', 'lon', 'alt']] = scaler.fit_transform(df[['lat', 'lon', 'alt']])\n",
        "\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "    df['day_sin'] = np.sin(2 * np.pi * df['datetime'].dt.dayofweek / 7)\n",
        "    df['day_cos'] = np.cos(2 * np.pi * df['datetime'].dt.dayofweek / 7)\n",
        "\n",
        "    user_ids = {user: idx for idx, user in enumerate(df['user'].unique())}\n",
        "    df['user_id'] = df['user'].map(user_ids)\n",
        "\n",
        "    df['grid_large_x'], df['grid_large_y'] = zip(*df.apply(lambda row: create_grid(row['lat'], row['lon'], GRID_SIZE_LARGE), axis=1))\n",
        "    df['grid_small_x'], df['grid_small_y'] = zip(*df.apply(lambda row: create_grid(row['lat'], row['lon'], GRID_SIZE_SMALL), axis=1))\n",
        "\n",
        "    return df, user_ids, scaler"
      ],
      "metadata": {
        "id": "TJ1fi_AgOmb_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 5. Подготовка последовательностей\n",
        "# ========================\n",
        "def prepare_sequences(df, seq_length=SEQ_LENGTH):\n",
        "    grouped = df.groupby('user_id')\n",
        "    data = []\n",
        "    for user_id, group in grouped:\n",
        "        group = group.reset_index(drop=True)\n",
        "        if len(group) < seq_length + 1:\n",
        "            continue\n",
        "        for i in range(len(group) - seq_length):\n",
        "            seq = group.iloc[i:i+seq_length+1]\n",
        "            traj = list(zip(seq['lat'], seq['lon'], seq['datetime']))\n",
        "            data.append((user_id, traj))\n",
        "    return data"
      ],
      "metadata": {
        "id": "IcXHUy2ZOpnM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 6. Контрастивная модель и обучение\n",
        "# ========================\n",
        "class ContrastiveEmbeddingModel(nn.Module):\n",
        "    def __init__(self, num_users, emb_dim):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(num_users, emb_dim)\n",
        "\n",
        "    def forward(self, user_ids):\n",
        "        return self.embeddings(user_ids)\n",
        "\n",
        "def contrastive_loss(z_i, z_j, temperature=0.5):\n",
        "    z_i = nn.functional.normalize(z_i, dim=1)\n",
        "    z_j = nn.functional.normalize(z_j, dim=1)\n",
        "    sim_matrix = torch.matmul(z_i, z_j.T) / temperature\n",
        "    labels = torch.arange(len(z_i)).to(z_i.device)\n",
        "    return nn.CrossEntropyLoss()(sim_matrix, labels)"
      ],
      "metadata": {
        "id": "0cC5lTegOsVh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 7. Dataset с полным эмбеддингом\n",
        "# ========================\n",
        "class TrajectoryDataset(Dataset):\n",
        "    def __init__(self, data, user_embeddings):\n",
        "        self.data = data\n",
        "        self.user_embeddings = user_embeddings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_id, traj = self.data[idx]\n",
        "        coords = torch.tensor([(x[0], x[1]) for x in traj], dtype=torch.float32)\n",
        "        times = [x[2] for x in traj]\n",
        "\n",
        "        # Генерация признаков\n",
        "        time_emb = sinusoidal_time_embedding(times)\n",
        "        user_emb = self.user_embeddings[user_id].repeat(len(traj), 1)\n",
        "\n",
        "        # Объединение признаков [coords(2) + time_emb(16) + user_emb(16) = 34]\n",
        "        inputs = torch.cat([coords, time_emb, user_emb], dim=1)\n",
        "        return inputs[:-1], coords[1:]"
      ],
      "metadata": {
        "id": "PFNYyt4GOvKs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 8. Крупномасштабная модель (LSTM)\n",
        "# ========================\n",
        "class MacroLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 2)  # lat, lon крупной ячейки\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out"
      ],
      "metadata": {
        "id": "RxKvkbAeOx0L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 9. Мелкомасштабная модель (Transformer)\n",
        "# ========================\n",
        "class MicroTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_heads=2, num_layers=2):  # 34 % 2 = 0\n",
        "        super().__init__()\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=input_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.fc = nn.Linear(input_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(1, 0, 2)  # [seq_len, batch, features]\n",
        "        out = self.transformer(x)\n",
        "        return self.fc(out[-1])"
      ],
      "metadata": {
        "id": "epGLChjLO4IB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 10. Интегрированная модель\n",
        "# ========================\n",
        "class DualScaleModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_heads=4, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.macro = MacroLSTM(input_dim, hidden_dim)\n",
        "        self.micro = MicroTransformer(input_dim, hidden_dim, num_heads, num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        macro_out = self.macro(x)\n",
        "        micro_out = self.micro(x)\n",
        "        return macro_out, micro_out"
      ],
      "metadata": {
        "id": "hdmsIfWzO6q8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 11. Функции обучения и валидации\n",
        "# ========================\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        macro_out, micro_out = model(x)\n",
        "        loss = criterion(micro_out, y[:, -1])  # Последняя точка\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            _, micro_out = model(x)\n",
        "            loss = criterion(micro_out, y[:, -1])\n",
        "            total_loss += loss.item()\n",
        "            all_preds.append(micro_out.cpu().numpy())\n",
        "            all_targets.append(y[:, -1].cpu().numpy())\n",
        "    return total_loss / len(dataloader), np.vstack(all_preds), np.vstack(all_targets)"
      ],
      "metadata": {
        "id": "ExqD5BXGO9DG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 12. Метрики\n",
        "# ========================\n",
        "def compute_metrics(preds, targets):\n",
        "    mse = mean_squared_error(targets, preds)\n",
        "    ade = np.mean([haversine(p, t) for p, t in zip(preds, targets)])\n",
        "    fde = np.mean([haversine(preds[i], targets[i]) for i in range(len(preds))])\n",
        "    acc_100m = np.mean([haversine(p, t) < 100 for p, t in zip(preds, targets)]) * 100\n",
        "    return {\n",
        "        \"MSE\": mse,\n",
        "        \"ADE\": ade,\n",
        "        \"FDE\": fde,\n",
        "        \"<100m %\": acc_100m\n",
        "    }"
      ],
      "metadata": {
        "id": "6EaPIrU-O_-z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Запуск обучения и тестирования\n",
        "# ========================\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка данных и подготовка последовательностей\n",
        "df, user_ids, scaler = load_and_preprocess_data(DATA_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdE3hlT4SMUH",
        "outputId": "325f78e8-8067-4cb8-de74-3120185977c2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading users: 100%|██████████| 3/3 [00:06<00:00,  2.14s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = prepare_sequences(df)"
      ],
      "metadata": {
        "id": "QoX-XKLySRtY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_triplets(data):\n",
        "    anchors, positives, negatives = [], [], []\n",
        "    user_trajs = {}\n",
        "    for uid, traj in data:\n",
        "        if uid not in user_trajs:\n",
        "            user_trajs[uid] = []\n",
        "        user_trajs[uid].append(traj)\n",
        "\n",
        "    for uid, trajs in user_trajs.items():\n",
        "        if len(trajs) < 2:\n",
        "            continue\n",
        "        for i in range(len(trajs)-1):\n",
        "            anchor = trajs[i]\n",
        "            positive = trajs[i+1]\n",
        "            other_uids = [u for u in user_trajs if u != uid]\n",
        "            neg_uid = random.choice(other_uids)\n",
        "            negative = random.choice(user_trajs[neg_uid])\n",
        "            anchors.append(anchor)\n",
        "            positives.append(positive)\n",
        "            negatives.append(negative)\n",
        "    return anchors, positives, negatives"
      ],
      "metadata": {
        "id": "rw1YvrnKWgUv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, 32, batch_first=True)\n",
        "        self.fc = nn.Linear(32, emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1])\n",
        "\n",
        "def triplet_loss(a, p, n, margin=1.0):\n",
        "    ap_dist = (a - p).pow(2).sum(1)\n",
        "    an_dist = (a - n).pow(2).sum(1)\n",
        "    loss = torch.relu(ap_dist - an_dist + margin)\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "vNeQ-Ob1Whux"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchors, positives, negatives = create_triplets(data)"
      ],
      "metadata": {
        "id": "8VD2hII8WmF4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_to_tensor(seqs):\n",
        "    tensors = []\n",
        "    for seq in seqs:\n",
        "        tensor = torch.tensor(\n",
        "            [[x[0], x[1]] for x in seq],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "        tensors.append(tensor)\n",
        "    return torch.stack(tensors)\n",
        "\n",
        "anchors_t = seq_to_tensor(anchors)\n",
        "positives_t = seq_to_tensor(positives)\n",
        "negatives_t = seq_to_tensor(negatives)"
      ],
      "metadata": {
        "id": "rE7PHm3IWneM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triplet_model = TripletEncoder(input_dim=2, emb_dim=EMBEDDING_DIM)\n",
        "optimizer = torch.optim.Adam(triplet_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "KjIf1U_QXJFH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "\n",
        "# Модифицируем цикл обучения:\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for a, p, n in zip(anchors_t, positives_t, negatives_t):\n",
        "        a = a.unsqueeze(0)\n",
        "        p = p.unsqueeze(0)\n",
        "        n = n.unsqueeze(0)\n",
        "\n",
        "        emb_a = triplet_model(a)\n",
        "        emb_p = triplet_model(p)\n",
        "        emb_n = triplet_model(n)\n",
        "\n",
        "        loss = triplet_loss(emb_a, emb_p, emb_n)  # Теперь используется встроенный лосс\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(anchors_t):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "PitdlraBXRw0",
        "outputId": "4fa79c33-9d9c-4331-e041-a06dd9c66b1e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 2.6291\n",
            "Epoch 2 | Loss: 1.4182\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-17f4df248ab0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplet_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_embeddings = {}\n",
        "with torch.no_grad():\n",
        "    for uid in user_ids.values():\n",
        "        user_seqs = [seq for seq in data if seq[0] == uid]\n",
        "        embeddings = []\n",
        "        for seq in user_seqs:\n",
        "            coords = torch.tensor([[x[0], x[1]] for x in seq[1]], dtype=torch.float32)\n",
        "            emb = triplet_model(coords.unsqueeze(0).to(device)).cpu()\n",
        "            embeddings.append(emb)\n",
        "        user_embeddings[uid] = torch.mean(torch.stack(embeddings), dim=0)"
      ],
      "metadata": {
        "id": "8XT2jj62ME85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for user_id, traj in data:\n",
        "    # Извлекаем все признаки из TrajectoryDataset\n",
        "    inputs, targets = TrajectoryDataset([(user_id, traj)], None)[0]  # None, так как user_embeddings пока не обучены\n",
        "    X.append(inputs.numpy())\n",
        "    y.append(targets.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "XDnLtXfASUVa",
        "outputId": "61c9bea5-68b4-4289-f6b8-e7e9c9c19cdd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ee34f8032bd1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Извлекаем все признаки из TrajectoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrajectoryDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# None, так как user_embeddings пока не обучены\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-60cc28d76f74>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtime_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinusoidal_time_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0muser_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mcoord_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoord_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X).squeeze()\n",
        "y = np.array(y).squeeze()"
      ],
      "metadata": {
        "id": "rnZDVVm8SdP5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "xrrer8FAPC8o"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(X_tensor, y_tensor)"
      ],
      "metadata": {
        "id": "eNHV9FenPG7F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int((1 - TEST_SIZE) * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "hVoAK1t8PKNk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация модели, оптимизатора и функции потерь\n",
        "model = DualScaleModel(input_dim=X.shape[2], hidden_dim=LSTM_UNITS).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "P_Glpc4yPOKt",
        "outputId": "5ae5e0e3-5f2d-400d-9dfb-e3a1541b64bb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "embed_dim must be divisible by num_heads",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7fdeb36227dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Инициализация модели, оптимизатора и функции потерь\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDualScaleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_UNITS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f3640175d337>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, hidden_dim, num_heads, num_layers)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmacro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMacroLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmicro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMicroTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-b95ccd399aa3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, hidden_dim, num_heads, num_layers)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mencoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformerEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# точная координата\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, norm_first, bias, device, dtype)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mfactory_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         self.self_attn = MultiheadAttention(\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mnhead\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         assert (\n\u001b[0;32m-> 1076\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m         ), \"embed_dim must be divisible by num_heads\"\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: embed_dim must be divisible by num_heads"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, preds, targets = evaluate(model, test_loader, criterion, device)\n",
        "    metrics = compute_metrics(preds, targets)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | MSE: {metrics['MSE']:.4f} | ADE: {metrics['ADE']:.2f}m | FDE: {metrics['FDE']:.2f}m | <100m: {metrics['<100m %']:.2f}%\")"
      ],
      "metadata": {
        "id": "bPSRT05oPRl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 14. Сохранение модели\n",
        "# ========================\n",
        "torch.save(model.state_dict(), \"dual_scale_model.pth\")\n",
        "print(\"Model saved as dual_scale_model.pth\")"
      ],
      "metadata": {
        "id": "0Edu8MlxPV6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 15. Визуализация предсказаний\n",
        "# ========================\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(targets[:, 1], targets[:, 0], c='blue', label='True', alpha=0.5)\n",
        "plt.scatter(preds[:, 1], preds[:, 0], c='red', label='Predicted', alpha=0.5)\n",
        "plt.title(\"Predicted vs True Trajectory Points\")\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nOjzRkdgPZ2L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}