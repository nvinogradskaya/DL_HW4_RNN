{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyME1G/Ieu8tXAtAgXRCsxwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvinogradskaya/DL_HW4_RNN/blob/main/LSTM%2BContrastive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c2M8C_JsKWBR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Concatenate, Input, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "SEQ_LENGTH = 10\n",
        "EMBEDDING_DIM = 16\n",
        "LSTM_UNITS = 64\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = \"/content/drive/My Drive/Colab Notebooks/Data/\"\n",
        "SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/contrastive_results/\"\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Aei32AOGKCn",
        "outputId": "d2810546-8a71-44f0-ffb2-b3d72da7a7ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(preds, targets):\n",
        "    # Средняя ошибка смещения (ADE)\n",
        "    ade = np.mean(np.linalg.norm(preds - targets, axis=-1))\n",
        "\n",
        "    # Финальная ошибка смещения (FDE)\n",
        "    fde = np.linalg.norm(preds[:, -1] - targets[:, -1], axis=-1).mean()\n",
        "\n",
        "    # Accuracy@1\n",
        "    distances = np.linalg.norm(preds[:, None] - targets[:, :, None], axis=-1)\n",
        "    acc1 = np.mean(np.argmin(distances, axis=-1) == 0)\n",
        "\n",
        "    return ade, fde, acc1"
      ],
      "metadata": {
        "id": "upJ6y5woGqIQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(data_path, max_users=10):\n",
        "    data = []\n",
        "    user_dirs = sorted(os.listdir(data_path))[:max_users]\n",
        "\n",
        "    for user in user_dirs:\n",
        "        traj_dir = os.path.join(data_path, user, 'Trajectory')\n",
        "        traj_files = [f for f in os.listdir(traj_dir) if f.endswith('.plt')]\n",
        "\n",
        "        for traj_file in traj_files:\n",
        "            df = pd.read_csv(\n",
        "                os.path.join(traj_dir, traj_file),\n",
        "                skiprows=6,\n",
        "                header=None,\n",
        "                usecols=[0, 1, 3, 5, 6],\n",
        "                names=['lat', 'lon', 'alt', 'date', 'time']\n",
        "            )\n",
        "            df['user'] = user\n",
        "            data.append(df)\n",
        "\n",
        "    df = pd.concat(data, ignore_index=True)\n",
        "    df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
        "    df.sort_values(by=['user', 'datetime'], inplace=True)\n",
        "    df = df[(df['lat'] != 0) & (df['lon'] != 0)].ffill()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    df[['lat', 'lon', 'alt']] = scaler.fit_transform(df[['lat', 'lon', 'alt']])\n",
        "\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "    df['day_sin'] = np.sin(2 * np.pi * df['datetime'].dt.dayofweek / 7)\n",
        "    df['day_cos'] = np.cos(2 * np.pi * df['datetime'].dt.dayofweek / 7)\n",
        "\n",
        "    user_ids = {user: idx for idx, user in enumerate(df['user'].unique())}\n",
        "    df['user_id'] = df['user'].map(user_ids)\n",
        "\n",
        "    return df, user_ids, scaler"
      ],
      "metadata": {
        "id": "7Cq_kIMrG4i_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, user_ids, scaler = load_and_preprocess_data(DATA_PATH)"
      ],
      "metadata": {
        "id": "_Y3G-kOMG_pE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_with_split(df, user_ids, seq_length, test_size=0.2):\n",
        "    X_train, X_test, y_train, y_test, users_train, users_test = [], [], [], [], [], []\n",
        "\n",
        "    for user, user_df in df.groupby('user'):\n",
        "        # Разделение траектории пользователя на train/test\n",
        "        split_idx = int(len(user_df) * (1 - test_size))\n",
        "\n",
        "        # Тренировочные последовательности\n",
        "        train_data = user_df.iloc[:split_idx]\n",
        "        for i in range(len(train_data) - seq_length):\n",
        "            X_train.append(train_data[features].values[i:i+seq_length])\n",
        "            y_train.append(train_data[targets].values[i+seq_length])\n",
        "            users_train.append(user_ids[user])\n",
        "\n",
        "        # Тестовые последовательности\n",
        "        test_data = user_df.iloc[split_idx-seq_length:]\n",
        "        for i in range(len(test_data) - seq_length):\n",
        "            X_test.append(test_data[features].values[i:i+seq_length])\n",
        "            y_test.append(test_data[targets].values[i+seq_length])\n",
        "            users_test.append(user_ids[user])\n",
        "\n",
        "    return (\n",
        "        np.array(X_train), np.array(X_test),\n",
        "        np.array(y_train), np.array(y_test),\n",
        "        np.array(users_train), np.array(users_test)\n",
        "    )"
      ],
      "metadata": {
        "id": "liXDSFUPIB86"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание последовательностей с временным разделением\n",
        "features = ['lat', 'lon', 'alt', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
        "targets = ['lat', 'lon']\n",
        "X_train, X_test, y_train, y_test, users_train, users_test = create_sequences_with_split(df, user_ids, SEQ_LENGTH)"
      ],
      "metadata": {
        "id": "7lcI0owMIKFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveModel(tf.keras.Model):\n",
        "    def __init__(self, num_users, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = Embedding(num_users, embedding_dim)\n",
        "        self.dense = Dense(embedding_dim, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_id = inputs\n",
        "        user_emb = self.embedding(user_id)\n",
        "        return self.dense(user_emb)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        users, _ = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            embeddings = self(users)\n",
        "            anchor = embeddings[:, 0]\n",
        "            positive = embeddings[:, 1]\n",
        "            distances = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "            loss = self.compiled_loss(None, distances)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        return {'loss': loss}"
      ],
      "metadata": {
        "id": "-tyAEHfmLQZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contrastive_model = ContrastiveModel(num_users=len(user_ids), embedding_dim=EMBEDDING_DIM)\n",
        "contrastive_model.compile(optimizer=Adam(0.001), loss=tf.keras.losses.MeanSquaredError())\n",
        "contrastive_model.fit(users_train, np.zeros(len(users_train)), epochs=5, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "_BH_OcNcLYzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание эмбеддингов пользователей\n",
        "user_embeddings = contrastive_model.predict(np.unique(users_train))\n",
        "\n",
        "# Объединение признаков\n",
        "def combine_features(X, users, embeddings):\n",
        "    embeddings_expanded = np.repeat(embeddings[users][:, np.newaxis, :], SEQ_LENGTH, axis=1)\n",
        "    return np.concatenate([X, embeddings_expanded], axis=-1)\n",
        "\n",
        "X_train_combined = combine_features(X_train, users_train, user_embeddings)\n",
        "X_test_combined = combine_features(X_test, users_test, user_embeddings)"
      ],
      "metadata": {
        "id": "8q4GE2u8LenV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_model(seq_length, embedding_dim, num_features, num_users):\n",
        "    seq_input = Input(shape=(seq_length, num_features))\n",
        "    user_input = Input(shape=(1,), dtype=tf.int32)\n",
        "\n",
        "    user_emb = Embedding(num_users, embedding_dim)(user_input)\n",
        "    user_emb = Reshape((embedding_dim,))(user_emb)\n",
        "\n",
        "    lstm_out = LSTM(LSTM_UNITS, return_sequences=False)(seq_input)\n",
        "    combined = Concatenate()([lstm_out, user_emb])\n",
        "\n",
        "    dense_out = Dense(64, activation='relu')(combined)\n",
        "    dense_out = Dense(32, activation='relu')(dense_out)\n",
        "    final_output = Dense(2, activation='linear')(dense_out)\n",
        "\n",
        "    model = Model(inputs=[seq_input, user_input], outputs=final_output)\n",
        "    model.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "pkBKMmTWLji6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_lstm_model()\n",
        "checkpoint = ModelCheckpoint(os.path.join(SAVE_PATH, 'best_model.h5'),\n",
        "                            save_best_only=True, monitor='val_loss')\n",
        "history = model.fit(\n",
        "    [X_train_combined, users_train], y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "aLTm4jCjLpp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(os.path.join(SAVE_PATH, 'best_model.h5'))\n",
        "y_pred = model.predict([X_test_combined, users_test])\n",
        "\n",
        "ade, fde, acc1 = calculate_metrics(y_pred, y_test)\n",
        "print(f\"ADE: {ade:.4f}, FDE: {fde:.4f}, Accuracy@1: {acc1:.4f}\")\n",
        "\n",
        "# Визуализация\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P2ChXk7DLv0K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}